{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUCdj1YuC1PzUe4NdrVEN5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elangbijak4/LLM-SLM-Examples/blob/main/Rev2_Hitung_Bobot_WQ_WK_WV_Layer_Enkoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LTjR7zK_KKTq",
        "outputId": "56cd07e2-8174-46f9-a0d6-5cde7df00ddf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Collecting h5py>=3.10.0 (from tensorflow)\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras>=3.0.0 (from tensorflow)\n",
            "  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
            "Collecting namex (from keras>=3.0.0->tensorflow)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Collecting optree (from keras>=3.0.0->tensorflow)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
            "Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.3.3 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "h5py",
                  "keras",
                  "ml_dtypes",
                  "tensorboard",
                  "tensorflow"
                ]
              },
              "id": "49a78e51087546508efdcbcc89a48139"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecjbix1_C-Rj",
        "outputId": "0a48461a-cf65-4d17-f0ab-c8821f03fd15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 9.210573196411133\n",
            "Embedding weights:\n",
            "[[-0.02512415  0.04174279 -0.04002928 ... -0.0102726   0.00034293\n",
            "   0.01374712]\n",
            " [ 0.03294295  0.03596812  0.0426126  ...  0.04474736 -0.00488594\n",
            "  -0.01463312]\n",
            " [-0.01046726  0.03904081 -0.05069197 ... -0.02469442  0.0338889\n",
            "   0.00599896]\n",
            " ...\n",
            " [-0.02806597 -0.0109309  -0.01019118 ... -0.03515537  0.03566002\n",
            "  -0.02802562]\n",
            " [-0.00375626 -0.00140073  0.03481344 ...  0.01442082  0.01386089\n",
            "   0.00569982]\n",
            " [ 0.0470213   0.00272004  0.00178163 ...  0.02184321 -0.0297488\n",
            "  -0.03445563]]\n",
            "LSTM weights:\n",
            "[array([[ 0.00336694,  0.0400167 , -0.0029756 , ...,  0.01870552,\n",
            "        -0.0404182 , -0.01368228],\n",
            "       [-0.03944996, -0.01463773, -0.0434203 , ..., -0.02625771,\n",
            "         0.00800121,  0.01783141],\n",
            "       [-0.04359723, -0.00613987,  0.01508364, ...,  0.03381531,\n",
            "         0.00322672,  0.02918964],\n",
            "       ...,\n",
            "       [-0.01126161, -0.00544745, -0.02711342, ...,  0.01078841,\n",
            "        -0.01612252, -0.01007359],\n",
            "       [-0.02091834, -0.04440208, -0.0252385 , ..., -0.0388331 ,\n",
            "        -0.02841084,  0.01455195],\n",
            "       [-0.03197929, -0.03888166, -0.04500955, ..., -0.0383562 ,\n",
            "         0.04516582, -0.02017542]], dtype=float32), array([[ 0.02619774,  0.01011499,  0.00418657, ...,  0.03839713,\n",
            "         0.01773669, -0.03657073],\n",
            "       [ 0.00560217, -0.05544695, -0.01759078, ..., -0.00136638,\n",
            "         0.04168585, -0.00085148],\n",
            "       [ 0.00354044,  0.04399193,  0.00631984, ...,  0.0131782 ,\n",
            "         0.01176988,  0.02459833],\n",
            "       ...,\n",
            "       [-0.02956654, -0.00591343, -0.01309556, ...,  0.00377586,\n",
            "         0.02851714, -0.00895855],\n",
            "       [-0.00519567, -0.01171412,  0.01071683, ...,  0.0069027 ,\n",
            "        -0.0058138 ,  0.0136179 ],\n",
            "       [-0.03746998,  0.02344589, -0.00712982, ..., -0.00213841,\n",
            "        -0.01918242, -0.0114109 ]], dtype=float32), array([ 0.00060339, -0.00083955,  0.00080294, ..., -0.00063252,\n",
            "        0.00070275,  0.00073384], dtype=float32)]\n",
            "Dense weights:\n",
            "[array([[-0.01676515,  0.02176122, -0.02062477, ..., -0.01048737,\n",
            "        -0.02236544, -0.00219605],\n",
            "       [-0.00847344, -0.01167405,  0.01947014, ..., -0.01633364,\n",
            "        -0.00074509,  0.00528688],\n",
            "       [-0.01796263,  0.00227408,  0.00226277, ...,  0.01137564,\n",
            "        -0.00465702, -0.00577601],\n",
            "       ...,\n",
            "       [-0.01878333, -0.01367152,  0.01844478, ...,  0.00604443,\n",
            "         0.00508056,  0.01137859],\n",
            "       [-0.02024544, -0.00790193, -0.00596184, ...,  0.00933238,\n",
            "        -0.01159751,  0.02252256],\n",
            "       [ 0.01130514, -0.02321502, -0.00452202, ..., -0.02385504,\n",
            "         0.01953337, -0.02327203]], dtype=float32), array([-0.00096934, -0.00096933,  0.00099997, ..., -0.00096939,\n",
            "       -0.00096937, -0.00096936], dtype=float32)]\n",
            "Epoch 2, Loss: 9.199914932250977\n",
            "Embedding weights:\n",
            "[[-0.02512415  0.04174279 -0.04002928 ... -0.0102726   0.00034293\n",
            "   0.01374712]\n",
            " [ 0.03390575  0.03696447  0.04360942 ...  0.0455406  -0.00393903\n",
            "  -0.0156313 ]\n",
            " [-0.01034385  0.04002456 -0.05166451 ... -0.0256765   0.03331672\n",
            "   0.0050039 ]\n",
            " ...\n",
            " [-0.02806597 -0.0109309  -0.01019118 ... -0.03515537  0.03566002\n",
            "  -0.02802562]\n",
            " [-0.00375626 -0.00140073  0.03481344 ...  0.01442082  0.01386089\n",
            "   0.00569982]\n",
            " [ 0.0470213   0.00272004  0.00178163 ...  0.02184321 -0.0297488\n",
            "  -0.03445563]]\n",
            "LSTM weights:\n",
            "[array([[ 0.0034509 ,  0.04001177, -0.00294452, ...,  0.01862247,\n",
            "        -0.04029207, -0.01345267],\n",
            "       [-0.03932187, -0.01473914, -0.04348978, ..., -0.02628157,\n",
            "         0.00816415,  0.01816799],\n",
            "       [-0.04352453, -0.00604967,  0.01505448, ...,  0.03389606,\n",
            "         0.00323735,  0.02892053],\n",
            "       ...,\n",
            "       [-0.01120604, -0.00550785, -0.02709194, ...,  0.01074954,\n",
            "        -0.01624818, -0.01024539],\n",
            "       [-0.02082078, -0.04443325, -0.02527198, ..., -0.03884024,\n",
            "        -0.02864272,  0.01422403],\n",
            "       [-0.03204887, -0.03908851, -0.04497113, ..., -0.03838488,\n",
            "         0.04507243, -0.0203441 ]], dtype=float32), array([[ 0.02619519,  0.01015252,  0.00417028, ...,  0.03840422,\n",
            "         0.01774497, -0.03653025],\n",
            "       [ 0.00559988, -0.05542628, -0.01759598, ..., -0.00135214,\n",
            "         0.04168886, -0.00083212],\n",
            "       [ 0.00353908,  0.04399903,  0.00632454, ...,  0.01316881,\n",
            "         0.0117747 ,  0.02461577],\n",
            "       ...,\n",
            "       [-0.02956464, -0.00592166, -0.01309601, ...,  0.00376743,\n",
            "         0.02853471, -0.00893185],\n",
            "       [-0.00519224, -0.01170295,  0.01070269, ...,  0.00691035,\n",
            "        -0.00581815,  0.01358605],\n",
            "       [-0.03746761,  0.0233769 , -0.00712879, ..., -0.00214655,\n",
            "        -0.01921662, -0.01154931]], dtype=float32), array([ 0.0013637 , -0.00155904,  0.00167552, ..., -0.00071482,\n",
            "        0.00151341,  0.00155548], dtype=float32)]\n",
            "Dense weights:\n",
            "[array([[-0.01673835,  0.02178804, -0.02157237, ..., -0.01046069,\n",
            "        -0.02233875, -0.0021693 ],\n",
            "       [-0.00838866, -0.01158922,  0.01854258, ..., -0.01624879,\n",
            "        -0.00066034,  0.00537176],\n",
            "       [-0.01800361,  0.00223318,  0.0012694 , ...,  0.01133467,\n",
            "        -0.00469807, -0.00581696],\n",
            "       ...,\n",
            "       [-0.01882589, -0.01371418,  0.01939651, ...,  0.00600183,\n",
            "         0.00503798,  0.01133597],\n",
            "       [-0.02016051, -0.00781695, -0.00694109, ...,  0.0094175 ,\n",
            "        -0.01151252,  0.02260757],\n",
            "       [ 0.01134236, -0.02317777, -0.00353304, ..., -0.02381748,\n",
            "         0.01957094, -0.02323478]], dtype=float32), array([-0.00194746, -0.00194745,  0.00199994, ..., -0.00194753,\n",
            "       -0.00194751, -0.00194751], dtype=float32)]\n",
            "Epoch 3, Loss: 9.188593864440918\n",
            "Embedding weights:\n",
            "[[-0.02512415  0.04174279 -0.04002928 ... -0.0102726   0.00034293\n",
            "   0.01374712]\n",
            " [ 0.03486137  0.03796321  0.04460833 ...  0.04638202 -0.00299969\n",
            "  -0.01663249]\n",
            " [-0.00972975  0.04100518 -0.05263587 ... -0.02666349  0.03353868\n",
            "   0.00400856]\n",
            " ...\n",
            " [-0.02806597 -0.0109309  -0.01019118 ... -0.03515537  0.03566002\n",
            "  -0.02802562]\n",
            " [-0.00375626 -0.00140073  0.03481344 ...  0.01442082  0.01386089\n",
            "   0.00569982]\n",
            " [ 0.0470213   0.00272004  0.00178163 ...  0.02184321 -0.0297488\n",
            "  -0.03445563]]\n",
            "LSTM weights:\n",
            "[array([[ 0.00359651,  0.04005939, -0.00288751, ...,  0.01854162,\n",
            "        -0.04010535, -0.01313119],\n",
            "       [-0.0391082 , -0.01479664, -0.04358419, ..., -0.02631825,\n",
            "         0.00837693,  0.01857739],\n",
            "       [-0.04341791, -0.00595768,  0.01503039, ...,  0.03394778,\n",
            "         0.0032458 ,  0.02856985],\n",
            "       ...,\n",
            "       [-0.01110037, -0.00554799, -0.02709398, ...,  0.01070491,\n",
            "        -0.01641021, -0.01046565],\n",
            "       [-0.02068609, -0.04448306, -0.0253168 , ..., -0.03882263,\n",
            "        -0.02891937,  0.01385488],\n",
            "       [-0.03215019, -0.0393493 , -0.04494433, ..., -0.03838712,\n",
            "         0.04493304, -0.02058257]], dtype=float32), array([[ 0.02618124,  0.01020102,  0.00413712, ...,  0.03839806,\n",
            "         0.01775005, -0.03648024],\n",
            "       [ 0.0055968 , -0.05540936, -0.01759574, ..., -0.00133943,\n",
            "         0.04168949, -0.00079957],\n",
            "       [ 0.00353759,  0.04401665,  0.006333  , ...,  0.01315824,\n",
            "         0.01178851,  0.02466908],\n",
            "       ...,\n",
            "       [-0.02956124, -0.00592495, -0.01310183, ...,  0.00375755,\n",
            "         0.02855811, -0.00889826],\n",
            "       [-0.00518921, -0.01170424,  0.01068482, ...,  0.00691466,\n",
            "        -0.00582833,  0.01352418],\n",
            "       [-0.03745985,  0.02328902, -0.00713699, ..., -0.00214579,\n",
            "        -0.01926565, -0.01176122]], dtype=float32), array([ 0.0021874 , -0.00192196,  0.00257715, ..., -0.00028884,\n",
            "        0.00237344,  0.00241725], dtype=float32)]\n",
            "Dense weights:\n",
            "[array([[-0.01666659,  0.02185986, -0.02251604, ..., -0.01038904,\n",
            "        -0.02226714, -0.00209756],\n",
            "       [-0.00832681, -0.01152721,  0.01781362, ..., -0.01618687,\n",
            "        -0.00059854,  0.0054337 ],\n",
            "       [-0.01806701,  0.00216994,  0.00027295, ...,  0.01127132,\n",
            "        -0.00476157, -0.00588033],\n",
            "       ...,\n",
            "       [-0.01884611, -0.01373453,  0.02025676, ...,  0.00598157,\n",
            "         0.00501774,  0.01131572],\n",
            "       [-0.02005771, -0.00771411, -0.0079105 , ...,  0.0095205 ,\n",
            "        -0.01140964,  0.02271048],\n",
            "       [ 0.01143692, -0.02308332, -0.00255499, ..., -0.02372261,\n",
            "         0.01966594, -0.02314013]], dtype=float32), array([-0.00292956, -0.00292953,  0.00299992, ..., -0.00292959,\n",
            "       -0.0029296 , -0.00292962], dtype=float32)]\n",
            "Epoch 4, Loss: 9.175835609436035\n",
            "Embedding weights:\n",
            "[[-0.02512415  0.04174279 -0.04002928 ... -0.0102726   0.00034293\n",
            "   0.01374712]\n",
            " [ 0.03581507  0.03896362  0.04561009 ...  0.04724847 -0.00206008\n",
            "  -0.01763693]\n",
            " [-0.00897093  0.0419819  -0.0536088  ... -0.02764817  0.03412429\n",
            "   0.00301071]\n",
            " ...\n",
            " [-0.02806597 -0.0109309  -0.01019118 ... -0.03515537  0.03566002\n",
            "  -0.02802562]\n",
            " [-0.00375626 -0.00140073  0.03481344 ...  0.01442082  0.01386089\n",
            "   0.00569982]\n",
            " [ 0.0470213   0.00272004  0.00178163 ...  0.02184321 -0.0297488\n",
            "  -0.03445563]]\n",
            "LSTM weights:\n",
            "[array([[ 0.00381532,  0.04017115, -0.00279444, ...,  0.01847019,\n",
            "        -0.0398482 , -0.01272057],\n",
            "       [-0.03880121, -0.01478572, -0.04370298, ..., -0.02636705,\n",
            "         0.00864697,  0.01905512],\n",
            "       [-0.04327535, -0.00587785,  0.01502557, ...,  0.03394128,\n",
            "         0.00325062,  0.02814506],\n",
            "       ...,\n",
            "       [-0.01093185, -0.00556417, -0.02713498, ...,  0.01065209,\n",
            "        -0.01661198, -0.01074145],\n",
            "       [-0.02050215, -0.04456181, -0.02538024, ..., -0.03877015,\n",
            "        -0.02924928,  0.01344829],\n",
            "       [-0.03229126, -0.03966307, -0.04494807, ..., -0.03835074,\n",
            "         0.04473848, -0.02090023]], dtype=float32), array([[ 0.02614482,  0.01025825,  0.00407791, ...,  0.0383632 ,\n",
            "         0.01774587, -0.03642235],\n",
            "       [ 0.00559716, -0.05539487, -0.0175832 , ..., -0.00132155,\n",
            "         0.04168809, -0.00074142],\n",
            "       [ 0.00353587,  0.04405085,  0.00634781, ...,  0.0131456 ,\n",
            "         0.01181707,  0.02478022],\n",
            "       ...,\n",
            "       [-0.02955898, -0.00592364, -0.01311819, ...,  0.00373918,\n",
            "         0.02858631, -0.00885983],\n",
            "       [-0.00518661, -0.01172524,  0.01066197, ...,  0.0069154 ,\n",
            "        -0.00584817,  0.01341625],\n",
            "       [-0.03744641,  0.02317416, -0.00716307, ..., -0.00213889,\n",
            "        -0.01933632, -0.01206187]], dtype=float32), array([ 0.00304484, -0.0018227 ,  0.00349428, ...,  0.00035335,\n",
            "        0.00326301,  0.00330355], dtype=float32)]\n",
            "Dense weights:\n",
            "[array([[-0.0165427 ,  0.02198386, -0.0234643 , ..., -0.01026527,\n",
            "        -0.02214344, -0.00197365],\n",
            "       [-0.00830761, -0.01150776,  0.01747755, ..., -0.01616757,\n",
            "        -0.00057945,  0.00545294],\n",
            "       [-0.01815552,  0.00208168, -0.00072608, ...,  0.01118289,\n",
            "        -0.00485024, -0.00596883],\n",
            "       ...,\n",
            "       [-0.01883054, -0.01371914,  0.02092901, ...,  0.00599709,\n",
            "         0.00503327,  0.01133128],\n",
            "       [-0.01993175, -0.0075881 , -0.00887222, ...,  0.00964667,\n",
            "        -0.01128356,  0.0228366 ],\n",
            "       [ 0.01159727, -0.02292322, -0.00159291, ..., -0.02356204,\n",
            "         0.01982681, -0.02297963]], dtype=float32), array([-0.00391404, -0.003914  ,  0.0039999 , ..., -0.00391399,\n",
            "       -0.00391407, -0.00391413], dtype=float32)]\n",
            "Epoch 5, Loss: 9.160700798034668\n",
            "Embedding weights:\n",
            "[[-0.02512415  0.04174279 -0.04002928 ... -0.0102726   0.00034293\n",
            "   0.01374712]\n",
            " [ 0.03676816  0.03996328  0.04661552 ...  0.04813152 -0.00111594\n",
            "  -0.01864406]\n",
            " [-0.00814784  0.04295271 -0.05458678 ... -0.02860015  0.03485776\n",
            "   0.00200766]\n",
            " ...\n",
            " [-0.02806597 -0.0109309  -0.01019118 ... -0.03515537  0.03566002\n",
            "  -0.02802562]\n",
            " [-0.00375626 -0.00140073  0.03481344 ...  0.01442082  0.01386089\n",
            "   0.00569982]\n",
            " [ 0.0470213   0.00272004  0.00178163 ...  0.02184321 -0.0297488\n",
            "  -0.03445563]]\n",
            "LSTM weights:\n",
            "[array([[ 0.00411578,  0.04035521, -0.00265163, ...,  0.01841728,\n",
            "        -0.03951348, -0.0122253 ],\n",
            "       [-0.03839962, -0.01469106, -0.04384365, ..., -0.02642572,\n",
            "         0.00898138,  0.01959909],\n",
            "       [-0.04309659, -0.00582693,  0.01505639, ...,  0.03384932,\n",
            "         0.00324992,  0.02765197],\n",
            "       ...,\n",
            "       [-0.01069023, -0.0055582 , -0.02723065, ...,  0.01058853,\n",
            "        -0.01685887, -0.01108216],\n",
            "       [-0.02025516, -0.04468115, -0.02547371, ..., -0.03867073,\n",
            "        -0.02964123,  0.01300144],\n",
            "       [-0.03248124, -0.04003121, -0.04500419, ..., -0.03826329,\n",
            "         0.04448131, -0.02130337]], dtype=float32), array([[ 0.02606987,  0.0103221 ,  0.00398063, ...,  0.03827914,\n",
            "         0.01772324, -0.03635559],\n",
            "       [ 0.00560893, -0.05537844, -0.01754882, ..., -0.00128594,\n",
            "         0.04168619, -0.00064021],\n",
            "       [ 0.00353347,  0.04411054,  0.00637286, ...,  0.01312848,\n",
            "         0.01186766,  0.02497246],\n",
            "       ...,\n",
            "       [-0.02956356, -0.00591958, -0.01315283, ...,  0.00369988,\n",
            "         0.02861659, -0.00881854],\n",
            "       [-0.00518481, -0.01177558,  0.01063105, ...,  0.006911  ,\n",
            "        -0.00588369,  0.01324259],\n",
            "       [-0.03742816,  0.02301916, -0.0072191 , ..., -0.00213239,\n",
            "        -0.01943842, -0.01246104]], dtype=float32), array([ 0.00392346, -0.00139543,  0.00442089, ...,  0.00110174,\n",
            "        0.00417271,  0.00420719], dtype=float32)]\n",
            "Dense weights:\n",
            "[array([[-0.01636237,  0.02216436, -0.02442069, ..., -0.01008509,\n",
            "        -0.02196339, -0.00179327],\n",
            "       [-0.00834748, -0.01154723,  0.01757978, ..., -0.01620728,\n",
            "        -0.00061944,  0.00541304],\n",
            "       [-0.01827105,  0.00196653, -0.00172744, ...,  0.01106751,\n",
            "        -0.00496602, -0.00608438],\n",
            "       ...,\n",
            "       [-0.01876828, -0.01365709,  0.02130092, ...,  0.00605923,\n",
            "         0.00509545,  0.01139358],\n",
            "       [-0.01977589, -0.00743223, -0.00982845, ...,  0.0098027 ,\n",
            "        -0.01112753,  0.02299268],\n",
            "       [ 0.01182787, -0.02269304, -0.00065212, ..., -0.02333135,\n",
            "         0.02005797, -0.02274881]], dtype=float32), array([-0.00490018, -0.00490011,  0.00499988, ..., -0.00490001,\n",
            "       -0.00490019, -0.00490032], dtype=float32)]\n",
            "Epoch 6, Loss: 9.142070770263672\n",
            "Embedding weights:\n",
            "[[-0.02512415  0.04174279 -0.04002928 ... -0.0102726   0.00034293\n",
            "   0.01374712]\n",
            " [ 0.03772039  0.0409576   0.04762539 ...  0.04902935 -0.00016509\n",
            "  -0.0196522 ]\n",
            " [-0.00728973  0.04391561 -0.05557233 ... -0.02942438  0.03566907\n",
            "   0.00099799]\n",
            " ...\n",
            " [-0.02806597 -0.0109309  -0.01019118 ... -0.03515537  0.03566002\n",
            "  -0.02802562]\n",
            " [-0.00375626 -0.00140073  0.03481344 ...  0.01442082  0.01386089\n",
            "   0.00569982]\n",
            " [ 0.0470213   0.00272004  0.00178163 ...  0.02184321 -0.0297488\n",
            "  -0.03445563]]\n",
            "LSTM weights:\n",
            "[array([[ 0.00450227,  0.0406191 , -0.00244307, ...,  0.01839702,\n",
            "        -0.03909721, -0.01165181],\n",
            "       [-0.03790739, -0.01450251, -0.04400061, ..., -0.02648959,\n",
            "         0.00938577,  0.02020672],\n",
            "       [-0.0428836 , -0.0058245 ,  0.01513952, ...,  0.03365246,\n",
            "         0.00324017,  0.02709567],\n",
            "       ...,\n",
            "       [-0.0103684 , -0.00553389, -0.02739601, ...,  0.01051311,\n",
            "        -0.01715704, -0.01149615],\n",
            "       [-0.01993256, -0.04485205, -0.02561191, ..., -0.03850958,\n",
            "        -0.0301015 ,  0.01250844],\n",
            "       [-0.03272962, -0.0404563 , -0.04513399, ..., -0.03811179,\n",
            "         0.04415612, -0.02179286]], dtype=float32), array([[ 0.02593544,  0.01038949,  0.00383049, ...,  0.03812131,\n",
            "         0.01766849, -0.03627537],\n",
            "       [ 0.00564544, -0.05535116, -0.01747941, ..., -0.00121265,\n",
            "         0.04168784, -0.00047395],\n",
            "       [ 0.00352898,  0.04420824,  0.00641382, ...,  0.01310191,\n",
            "         0.01194931,  0.02526488],\n",
            "       ...,\n",
            "       [-0.02958561, -0.00591671, -0.01321724, ...,  0.00362012,\n",
            "         0.02864274, -0.00877707],\n",
            "       [-0.00518521, -0.01186848,  0.01058573, ...,  0.00689688,\n",
            "        -0.00594441,  0.01298319],\n",
            "       [-0.03740763,  0.02280683, -0.007321  , ..., -0.00213882,\n",
            "        -0.01958516, -0.01295939]], dtype=float32), array([ 0.00481689, -0.00077654,  0.00535408, ...,  0.00191051,\n",
            "        0.00509675,  0.00512411], dtype=float32)]\n",
            "Dense weights:\n",
            "[array([[-0.01612294,  0.02240404, -0.02538694, ..., -0.00984583,\n",
            "        -0.0217243 , -0.00155371],\n",
            "       [-0.00845816, -0.01165738,  0.01799442, ..., -0.0163177 ,\n",
            "        -0.00073027,  0.00530222],\n",
            "       [-0.01841485,  0.00182331, -0.00273078, ...,  0.01092397,\n",
            "        -0.00511018, -0.00622825],\n",
            "       ...,\n",
            "       [-0.01865021, -0.01353923,  0.02131982, ...,  0.00617714,\n",
            "         0.00521341,  0.01151177],\n",
            "       [-0.01958236, -0.00723875, -0.01078191, ...,  0.00999635,\n",
            "        -0.01093377,  0.02318651],\n",
            "       [ 0.01213037, -0.02239111,  0.00026195, ..., -0.02302889,\n",
            "         0.02036109, -0.022446  ]], dtype=float32), array([-0.00588757, -0.00588747,  0.00599986, ..., -0.00588724,\n",
            "       -0.00588755, -0.00588778], dtype=float32)]\n",
            "Epoch 7, Loss: 9.118570327758789\n",
            "Embedding weights:\n",
            "[[-2.5124146e-02  4.1742790e-02 -4.0029276e-02 ... -1.0272600e-02\n",
            "   3.4292787e-04  1.3747122e-02]\n",
            " [ 3.8670786e-02  4.1941397e-02  4.8640396e-02 ...  4.9942669e-02\n",
            "   7.9349196e-04 -2.0658661e-02]\n",
            " [-6.4103096e-03  4.4870041e-02 -5.6567263e-02 ... -2.9931240e-02\n",
            "   3.6530077e-02 -1.6867765e-05]\n",
            " ...\n",
            " [-2.8065968e-02 -1.0930896e-02 -1.0191180e-02 ... -3.5155367e-02\n",
            "   3.5660017e-02 -2.8025616e-02]\n",
            " [-3.7562624e-03 -1.4007315e-03  3.4813438e-02 ...  1.4420819e-02\n",
            "   1.3860885e-02  5.6998245e-03]\n",
            " [ 4.7021303e-02  2.7200356e-03  1.7816313e-03 ...  2.1843206e-02\n",
            "  -2.9748797e-02 -3.4455635e-02]]\n",
            "LSTM weights:\n",
            "[array([[ 0.0049748 ,  0.04096968, -0.00215374, ...,  0.01842928,\n",
            "        -0.03859911, -0.01100804],\n",
            "       [-0.0373321 , -0.01421244, -0.04416283, ..., -0.0265485 ,\n",
            "         0.0098633 ,  0.02087396],\n",
            "       [-0.04264124, -0.00588984,  0.01529096, ...,  0.03334083,\n",
            "         0.00321584,  0.02648085],\n",
            "       ...,\n",
            "       [-0.00996277, -0.00549531, -0.02764404, ...,  0.01042728,\n",
            "        -0.01751248, -0.01198797],\n",
            "       [-0.0195257 , -0.04508323, -0.02581171, ..., -0.0382711 ,\n",
            "        -0.03063262,  0.01196284],\n",
            "       [-0.03304509, -0.04094128, -0.04535532, ..., -0.03788394,\n",
            "         0.04375939, -0.02236423]], dtype=float32), array([[ 0.02571831,  0.01045376,  0.00361142, ...,  0.03786586,\n",
            "         0.01756227, -0.03617268],\n",
            "       [ 0.0057267 , -0.05529676, -0.01735779, ..., -0.00107431,\n",
            "         0.04170214, -0.00021934],\n",
            "       [ 0.00351884,  0.04436031,  0.00647886, ...,  0.01305678,\n",
            "         0.01207281,  0.02566684],\n",
            "       ...,\n",
            "       [-0.0296431 , -0.00592326, -0.01332724, ...,  0.00347337,\n",
            "         0.02865137, -0.00874115],\n",
            "       [-0.00519164, -0.01202121,  0.01051443, ...,  0.00686246,\n",
            "        -0.00604492,  0.01262309],\n",
            "       [-0.03739033,  0.02251844, -0.00748788, ..., -0.00217927,\n",
            "        -0.01979289, -0.01354847]], dtype=float32), array([ 5.7215253e-03, -4.5641034e-05,  6.2924633e-03, ...,\n",
            "        2.7568103e-03,  6.0307495e-03,  6.0516298e-03], dtype=float32)]\n",
            "Dense weights:\n",
            "[array([[-0.01582274,  0.02270458, -0.02636404, ..., -0.00954585,\n",
            "        -0.02142454, -0.00125335],\n",
            "       [-0.00864743, -0.01184598,  0.01860137, ..., -0.01650658,\n",
            "        -0.0009197 ,  0.00511271],\n",
            "       [-0.01858775,  0.00165126, -0.00373551, ...,  0.01075143,\n",
            "        -0.00528364, -0.0064013 ],\n",
            "       ...,\n",
            "       [-0.01846834, -0.01335761,  0.02103097, ...,  0.00635873,\n",
            "         0.00539511,  0.01169382],\n",
            "       [-0.01934273, -0.00699927, -0.01173584, ...,  0.01023599,\n",
            "        -0.01069386,  0.0234265 ],\n",
            "       [ 0.01250451, -0.02201773,  0.0011439 , ..., -0.02265495,\n",
            "         0.02073591, -0.02207146]], dtype=float32), array([-0.00687597, -0.00687582,  0.00699984, ..., -0.00687542,\n",
            "       -0.00687592, -0.00687627], dtype=float32)]\n",
            "Epoch 8, Loss: 9.088458061218262\n",
            "Embedding weights:\n",
            "[[-0.02512415  0.04174279 -0.04002928 ... -0.0102726   0.00034293\n",
            "   0.01374712]\n",
            " [ 0.03961841  0.04291152  0.04966096 ...  0.05087292  0.00176044\n",
            "  -0.02166013]\n",
            " [-0.00551659  0.04581735 -0.05757309 ... -0.02999625  0.0374272\n",
            "  -0.00103223]\n",
            " ...\n",
            " [-0.02806597 -0.0109309  -0.01019118 ... -0.03515537  0.03566002\n",
            "  -0.02802562]\n",
            " [-0.00375626 -0.00140073  0.03481344 ...  0.01442082  0.01386089\n",
            "   0.00569982]\n",
            " [ 0.0470213   0.00272004  0.00178163 ...  0.02184321 -0.0297488\n",
            "  -0.03445563]]\n",
            "LSTM weights:\n",
            "[array([[ 0.00552931,  0.04141104, -0.00177353, ...,  0.01853691,\n",
            "        -0.03802266, -0.01030282],\n",
            "       [-0.03668334, -0.01381714, -0.04430875, ..., -0.02658094,\n",
            "         0.01041403,  0.02159521],\n",
            "       [-0.04237878, -0.00603956,  0.01552464, ...,  0.0329148 ,\n",
            "         0.00316893,  0.02581196],\n",
            "       ...,\n",
            "       [-0.00947327, -0.00544655, -0.0279839 , ...,  0.010337  ,\n",
            "        -0.01793019, -0.01255703],\n",
            "       [-0.01903191, -0.04538054, -0.02608985, ..., -0.03794243,\n",
            "        -0.03123305,  0.01136011],\n",
            "       [-0.03343431, -0.0414884 , -0.04567944, ..., -0.03757025,\n",
            "         0.04328961, -0.02300918]], dtype=float32), array([[ 0.02539912,  0.01049881,  0.00330898, ...,  0.0374975 ,\n",
            "         0.01738017, -0.03603486],\n",
            "       [ 0.00587855, -0.0551889 , -0.01716411, ..., -0.00084108,\n",
            "         0.04174713,  0.00014153],\n",
            "       [ 0.00349549,  0.04458568,  0.00657976, ...,  0.01297871,\n",
            "         0.01225028,  0.0261755 ],\n",
            "       ...,\n",
            "       [-0.0297622 , -0.0059555 , -0.01350219, ...,  0.00323098,\n",
            "         0.02861778, -0.00872559],\n",
            "       [-0.00521273, -0.01225363,  0.01039842, ...,  0.00678706,\n",
            "        -0.0062057 ,  0.01215754],\n",
            "       [-0.03738689,  0.02213837, -0.00773945, ..., -0.00228406,\n",
            "        -0.02007916, -0.01421397]], dtype=float32), array([0.00663534, 0.00075192, 0.00723549, ..., 0.0036279 , 0.00697098,\n",
            "       0.00698785], dtype=float32)]\n",
            "Dense weights:\n",
            "[array([[-0.01546089,  0.02306688, -0.02735269, ..., -0.00918427,\n",
            "        -0.02106322, -0.00089129],\n",
            "       [-0.00891981, -0.01211753,  0.01932951, ..., -0.01677843,\n",
            "        -0.00119228,  0.00483997],\n",
            "       [-0.01879062,  0.00144963, -0.00474063, ...,  0.01054906,\n",
            "        -0.0054873 , -0.00660443],\n",
            "       ...,\n",
            "       [-0.01821605, -0.0131056 ,  0.02052031, ...,  0.00661062,\n",
            "         0.00564721,  0.01194637],\n",
            "       [-0.01904869, -0.0067055 , -0.01269408, ...,  0.01052993,\n",
            "        -0.01039943,  0.02372101],\n",
            "       [ 0.01294873, -0.02157445,  0.00198783, ..., -0.02221108,\n",
            "         0.02118086, -0.02162677]], dtype=float32), array([-0.00786523, -0.007865  ,  0.00799982, ..., -0.0078644 ,\n",
            "       -0.00786514, -0.00786565], dtype=float32)]\n",
            "Epoch 9, Loss: 9.049463272094727\n",
            "Embedding weights:\n",
            "[[-0.02512415  0.04174279 -0.04002928 ... -0.0102726   0.00034293\n",
            "   0.01374712]\n",
            " [ 0.04056284  0.04386806  0.05068702 ...  0.05182157  0.00273647\n",
            "  -0.02265354]\n",
            " [-0.0046121   0.04676023 -0.05859064 ... -0.02970493  0.03835307\n",
            "  -0.00204198]\n",
            " ...\n",
            " [-0.02806597 -0.0109309  -0.01019118 ... -0.03515537  0.03566002\n",
            "  -0.02802562]\n",
            " [-0.00375626 -0.00140073  0.03481344 ...  0.01442082  0.01386089\n",
            "   0.00569982]\n",
            " [ 0.0470213   0.00272004  0.00178163 ...  0.02184321 -0.0297488\n",
            "  -0.03445563]]\n",
            "LSTM weights:\n",
            "[array([[ 0.00615873,  0.04194211, -0.00129961, ...,  0.01874144,\n",
            "        -0.03737466, -0.00954525],\n",
            "       [-0.03597135, -0.01331934, -0.04439707, ..., -0.02655057,\n",
            "         0.01103473,  0.02236383],\n",
            "       [-0.04211285, -0.00628654,  0.01585068, ...,  0.03238352,\n",
            "         0.00308829,  0.02509324],\n",
            "       ...,\n",
            "       [-0.00890334, -0.00539183, -0.02841931, ...,  0.01025656,\n",
            "        -0.01841363, -0.01319786],\n",
            "       [-0.01845476, -0.0457469 , -0.02645922, ..., -0.03751703,\n",
            "        -0.03189795,  0.01069954],\n",
            "       [-0.03390075, -0.04209803, -0.04610914, ..., -0.03716609,\n",
            "         0.04274744, -0.02371754]], dtype=float32), array([[ 0.02496919,  0.01048971,  0.00291389, ...,  0.03701527,\n",
            "         0.01709769, -0.03584866],\n",
            "       [ 0.00612737, -0.05499294, -0.01687942, ..., -0.00049101,\n",
            "         0.04185333,  0.0006138 ],\n",
            "       [ 0.00344505,  0.04490209,  0.00673297, ...,  0.01284858,\n",
            "         0.01249427,  0.02677806],\n",
            "       ...,\n",
            "       [-0.02997334, -0.00604207, -0.01376182, ...,  0.0028724 ,\n",
            "         0.02850612, -0.00876271],\n",
            "       [-0.00526514, -0.01258393,  0.01021219, ...,  0.00663791,\n",
            "        -0.006451  ,  0.01159351],\n",
            "       [-0.03741497,  0.02165962, -0.0080912 , ..., -0.0024881 ,\n",
            "        -0.02045873, -0.01493978]], dtype=float32), array([0.00755729, 0.00158918, 0.00818311, ..., 0.0045162 , 0.00791419,\n",
            "       0.00793134], dtype=float32)]\n",
            "Dense weights:\n",
            "[array([[-0.01503711,  0.0234912 , -0.02835346, ..., -0.00876083,\n",
            "        -0.02064005, -0.00046726],\n",
            "       [-0.00927694, -0.01247367,  0.02013944, ..., -0.01713488,\n",
            "        -0.00154967,  0.0044824 ],\n",
            "       [-0.01902466,  0.00121738, -0.00574445, ...,  0.01031569,\n",
            "        -0.0057225 , -0.00683888],\n",
            "       ...,\n",
            "       [-0.01788846, -0.01277834,  0.01985994, ...,  0.00693768,\n",
            "         0.00597459,  0.01227429],\n",
            "       [-0.01869293, -0.0063502 , -0.01366068, ...,  0.01088542,\n",
            "        -0.01004321,  0.02407729],\n",
            "       [ 0.01346062, -0.0210637 ,  0.00278737, ..., -0.02169969,\n",
            "         0.02169355, -0.02111436]], dtype=float32), array([-0.00885524, -0.0088549 ,  0.0089998 , ..., -0.00885407,\n",
            "       -0.00885514, -0.00885581], dtype=float32)]\n",
            "Epoch 10, Loss: 8.99856948852539\n",
            "Embedding weights:\n",
            "[[-0.02512415  0.04174279 -0.04002928 ... -0.0102726   0.00034293\n",
            "   0.01374712]\n",
            " [ 0.04150432  0.0448137   0.05171758 ...  0.05279003  0.00372256\n",
            "  -0.02363698]\n",
            " [-0.00369846  0.0477019  -0.0596171  ... -0.0291863   0.03930347\n",
            "  -0.00304162]\n",
            " ...\n",
            " [-0.02806597 -0.0109309  -0.01019118 ... -0.03515537  0.03566002\n",
            "  -0.02802562]\n",
            " [-0.00375626 -0.00140073  0.03481344 ...  0.01442082  0.01386089\n",
            "   0.00569982]\n",
            " [ 0.0470213   0.00272004  0.00178163 ...  0.02184321 -0.0297488\n",
            "  -0.03445563]]\n",
            "LSTM weights:\n",
            "[array([[ 0.00685421,  0.04255595, -0.00073629, ...,  0.01905789,\n",
            "        -0.03666404, -0.00874402],\n",
            "       [-0.03520599, -0.01272859, -0.04436969, ..., -0.02641652,\n",
            "         0.01171941,  0.02317288],\n",
            "       [-0.04187444, -0.00663803,  0.01627372, ...,  0.03176152,\n",
            "         0.00295913,  0.02432878],\n",
            "       ...,\n",
            "       [-0.00825967, -0.0053359 , -0.02894774, ...,  0.01021465,\n",
            "        -0.01896431, -0.01390187],\n",
            "       [-0.01780263, -0.0461827 , -0.02692515, ..., -0.0369963 ,\n",
            "        -0.03262052,  0.00998468],\n",
            "       [-0.03444432, -0.04276795, -0.04663898, ..., -0.0366723 ,\n",
            "         0.04213565, -0.024479  ]], dtype=float32), array([[ 2.4433395e-02,  1.0376179e-02,  2.4242806e-03, ...,\n",
            "         3.6431771e-02,  1.6699519e-02, -3.5604931e-02],\n",
            "       [ 6.4909840e-03, -5.4677770e-02, -1.6491070e-02, ...,\n",
            "        -2.0011241e-05,  4.2060245e-02,  1.1877592e-03],\n",
            "       [ 3.3456585e-03,  4.5320503e-02,  6.9591030e-03, ...,\n",
            "         1.2645847e-02,  1.2816303e-02,  2.7456887e-02],\n",
            "       ...,\n",
            "       [-3.0300682e-02, -6.2227715e-03, -1.4120957e-02, ...,\n",
            "         2.3945505e-03,  2.8278107e-02, -8.9015272e-03],\n",
            "       [-5.3757913e-03, -1.3022013e-02,  9.9292016e-03, ...,\n",
            "         6.3778078e-03, -6.8020415e-03,  1.0946246e-02],\n",
            "       [-3.7499506e-02,  2.1086788e-02, -8.5491883e-03, ...,\n",
            "        -2.8182010e-03, -2.0938288e-02, -1.5711090e-02]], dtype=float32), array([0.00848694, 0.00245022, 0.0091356 , ..., 0.00541714, 0.00885766,\n",
            "       0.00888107], dtype=float32)]\n",
            "Dense weights:\n",
            "[array([[-1.45517057e-02,  2.39772275e-02, -2.93668080e-02, ...,\n",
            "        -8.27584788e-03, -2.01553404e-02,  1.83986558e-05],\n",
            "       [-9.71785840e-03, -1.29134180e-02,  2.10085399e-02, ...,\n",
            "        -1.75749734e-02, -1.99090783e-03,  4.04100027e-03],\n",
            "       [-1.92916151e-02,  9.52989853e-04, -6.74437825e-03, ...,\n",
            "         1.00496151e-02, -5.99110452e-03, -7.10642384e-03],\n",
            "       ...,\n",
            "       [-1.74828619e-02, -1.23731531e-02,  1.90977231e-02, ...,\n",
            "         7.34259142e-03,  6.37999550e-03,  1.26802400e-02],\n",
            "       [-1.82700902e-02, -5.92802698e-03, -1.46393450e-02, ...,\n",
            "         1.13078142e-02, -9.61979944e-03,  2.45006923e-02],\n",
            "       [ 1.40371695e-02, -2.04884727e-02,  3.53538431e-03, ...,\n",
            "        -2.11237650e-02,  2.22709570e-02, -2.05372702e-02]], dtype=float32), array([-0.00984596, -0.00984545,  0.00999978, ..., -0.00984436,\n",
            "       -0.00984588, -0.00984671], dtype=float32)]\n",
            "Training selesai!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Fungsi untuk membuat model Language Model\n",
        "def build_language_model(vocab_size, embedding_dim, lstm_units):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True),\n",
        "        tf.keras.layers.LSTM(lstm_units, return_sequences=True),\n",
        "        tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(vocab_size, activation='softmax'))\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Contoh data input dan target\n",
        "input_data = tf.constant([[1, 2, 3, 4], [5, 6, 7, 8]])  # Contoh batch dengan panjang sekuens 4\n",
        "target_data = tf.constant([[2, 3, 4, 5], [6, 7, 8, 9]])  # Target adalah token selanjutnya dalam setiap sekuens\n",
        "\n",
        "# Hyperparameters\n",
        "vocab_size = 10000\n",
        "embedding_dim = 256\n",
        "lstm_units = 512\n",
        "learning_rate = 0.001\n",
        "batch_size = 2\n",
        "num_epochs = 10\n",
        "\n",
        "# Inisialisasi model\n",
        "model = build_language_model(vocab_size, embedding_dim, lstm_units)\n",
        "\n",
        "# Inisialisasi optimizer dan loss function\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "loss_fn = SparseCategoricalCrossentropy()\n",
        "\n",
        "# Ubah data input dan target menjadi objek Dataset\n",
        "input_dataset = tf.data.Dataset.from_tensor_slices(input_data)\n",
        "target_dataset = tf.data.Dataset.from_tensor_slices(target_data)\n",
        "\n",
        "# Gabungkan input dan target menjadi satu dataset\n",
        "dataset = tf.data.Dataset.zip((input_dataset, target_dataset))\n",
        "\n",
        "# Batch dataset\n",
        "batched_dataset = dataset.batch(batch_size)\n",
        "\n",
        "# Proses pelatihan\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for batch_inputs, batch_targets in batched_dataset:\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            predictions = model(batch_inputs)\n",
        "            loss = loss_fn(batch_targets, predictions)\n",
        "\n",
        "        # Hitung gradien\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "        # Update bobot model menggunakan optimizer Adam\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        total_loss += loss\n",
        "\n",
        "    avg_loss = total_loss / (len(input_data) // batch_size)\n",
        "    print(f'Epoch {epoch + 1}, Loss: {avg_loss}')\n",
        "\n",
        "    # Tampilkan bobot dari layer Embedding, LSTM, dan Dense\n",
        "    print(\"Embedding weights:\")\n",
        "    print(model.layers[0].get_weights()[0])  # Bobot layer Embedding\n",
        "    print(\"LSTM weights:\")\n",
        "    print(model.layers[1].get_weights())     # Bobot layer LSTM\n",
        "    print(\"Dense weights:\")\n",
        "    print(model.layers[2].get_weights())     # Bobot layer Dense\n",
        "\n",
        "print(\"Training selesai!\")"
      ]
    }
  ]
}